{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dafdad-72a1-447d-b945-442f30ce671a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    WORKING_DIR\n",
    "except NameError:\n",
    "    WORKING_DIR = Path.cwd().parent.parent\n",
    "\n",
    "%cd $WORKING_DIR\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bcb94a-9e25-4db6-9472-e9a6a257448c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pymoo.indicators.hv import HV\n",
    "import pfevaluator\n",
    "import pandas as pd\n",
    "\n",
    "from notebooks.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e077d4f1-7037-4c6b-b5bb-efb22a13beb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "volume_metrics = [\"HV\"]\n",
    "hv_slide = 100\n",
    "moo_metrics = list()\n",
    "datasets = [\"adult\", \"dutch\", \"credit\", \"compas\"]\n",
    "# datasets = [\"adult\"]\n",
    "\n",
    "# The maximum single point\n",
    "worse_recon_error_dict = dict(adult=1, dutch=1, credit=3, compas=1)\n",
    "worse_prop_val_dict = dict(leakage=1, discrimination=1)\n",
    "for dataset in datasets:\n",
    "    path = f\"results/alpha-beta-tradeoff/{dataset}/best.tinydb\"\n",
    "    print(path)\n",
    "    ab_table = AlphaBetaTradeoffTable([path])\n",
    "\n",
    "    cpf, cfb, ibsi, cpfsi = ab_table.get_tables(\n",
    "        aggregate=False,\n",
    "        latent_dim=32,\n",
    "    )\n",
    "\n",
    "    for property_ in (\"discrimination\", \"leakage\"):\n",
    "        cpf, cfb, ibsi, cpfsi = remove_stratified_metrics(cpf, cfb, ibsi, cpfsi)\n",
    "        results = [(\"CPF\", cpf), (\"CFB\", cfb), (\"IBSI\", ibsi), (\"CPFSI\", cpfsi)]\n",
    "        model_solutions = dict()\n",
    "        for model, result in results:\n",
    "            if not result.index.name == \"estimator\":\n",
    "                result.set_index(\"estimator\", inplace=True)\n",
    "\n",
    "            solutions = dict()\n",
    "            for estimator in [\"lr\", \"rf\"]:\n",
    "                res = result.loc[estimator, :]\n",
    "                table = pivot_table(res)\n",
    "                solution_table = get_solutions(table, property_)\n",
    "                solutions[estimator] = solution_table\n",
    "            assert all(solutions[\"lr\"].index == solutions[\"rf\"].index)\n",
    "\n",
    "            expansions = list()\n",
    "            for idx in solutions[\"lr\"].index:\n",
    "                columns = solutions[\"lr\"].columns\n",
    "                index_names = solutions[\"lr\"].index.names\n",
    "                t1 = solutions[\"lr\"].loc[idx].tolist()\n",
    "                t2 = solutions[\"rf\"].loc[idx].tolist()\n",
    "                if property_ == \"discrimination\":\n",
    "                    t1 = [t1[0], [t1[1], t1[2]]]\n",
    "                    t2 = [t2[0], [t2[1], t2[2]]]\n",
    "                expansion = expand_solutions(t1, t2)\n",
    "                if property_ == \"discrimination\":\n",
    "                    expansion = [flatten(t) for t in expansion]\n",
    "                tmp = pd.DataFrame(expansion, columns=columns)\n",
    "                for col, val in zip(index_names, idx):\n",
    "                    tmp[col] = val\n",
    "                tmp.set_index(index_names, inplace=True)\n",
    "                expansions.append(tmp)\n",
    "            expanded_solutions = pd.concat(expansions)\n",
    "            model_solutions[model] = expanded_solutions\n",
    "\n",
    "        all_solution_table = pd.concat(list(model_solutions.values()))\n",
    "        display(all_solution_table.max())\n",
    "        matrix_fitness = all_solution_table.to_numpy()\n",
    "        reference_front = pfevaluator.find_reference_front(matrix_fitness)\n",
    "\n",
    "        ref_point = np.array([worse_recon_error_dict[dataset], worse_prop_val_dict[property_], 1.0])\n",
    "        for model, model_solution_table in model_solutions.items():\n",
    "            for key, group in model_solution_table.groupby(\"seed\"):\n",
    "                data = group.to_numpy()\n",
    "\n",
    "                with hidden_prints():\n",
    "                    volume_metrics_values = pfevaluator.metric_volume(\n",
    "                        hv_slide + data,\n",
    "                        reference_front=reference_front,\n",
    "                        metrics=volume_metrics,\n",
    "                        hv_point=ref_point,\n",
    "                    )\n",
    "                \n",
    "                hv = HV(ref_point=ref_point)\n",
    "\n",
    "                nondom_data = pareto.eps_sort(data)\n",
    "                c1r_value = c1r(nondom_data, reference_front)\n",
    "                c2r_value = c2r(nondom_data, reference_front)\n",
    "                hv_value = hv(np.array(nondom_data))\n",
    "\n",
    "                entry = dict(\n",
    "                    Dataset=dataset,\n",
    "                    Property=property_,\n",
    "                    Model=model,\n",
    "                    seed=key,\n",
    "                    c1r=c1r_value,\n",
    "                    c2r=c2r_value,\n",
    "                    hv=hv_value,\n",
    "                    **volume_metrics_values,\n",
    "                )\n",
    "\n",
    "                moo_metrics.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd896774-c76f-483b-ac3c-47117923ffa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_drop = [\"seed\", \"HV\"]\n",
    "# pd.set_eng_float_format(accuracy=2, use_eng_prefix=True)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "df = pd.DataFrame(moo_metrics).drop(to_drop, axis=1)\n",
    "df = df.groupby([\"Dataset\", \"Property\", \"Model\"], sort=False).agg([np.mean, stderr])\n",
    "(df * 100).round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
